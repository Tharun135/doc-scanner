#!/usr/bin/env python3
"""
Quick Test: DocScanner Ollama RAG Upgrades
Tests better models and custom knowledge features
"""

import sys
import json
import os

# Add current directory to path  
sys.path.append('.')

def create_sample_custom_rules():
    """Create sample custom writing rules"""
    print("üìö Creating Sample Custom Writing Rules")
    print("=" * 40)
    
    # Sample custom rules for technical writing
    custom_rules = [
        {
            "text": "Use 'you' instead of 'the user' for direct communication. This makes instructions more personal and engaging.",
            "category": "technical_writing",
            "examples": ["Click the button", "Enter your password", "Select your preferred option"]
        },
        {
            "text": "Avoid hedging language like 'might', 'perhaps', 'possibly' in technical documentation. Be definitive and clear.",
            "category": "clarity", 
            "examples": ["The system will restart", "This method returns", "Click Save to continue"]
        },
        {
            "text": "Use parallel structure in lists and sequences. Keep verb forms consistent throughout instructions.",
            "category": "consistency",
            "examples": ["Save, edit, and publish", "Configure settings, test connections, deploy changes"]
        },
        {
            "text": "Write error messages that explain what happened and what to do next. Avoid technical jargon.",
            "category": "error_handling",
            "examples": ["File not found. Check the file path and try again.", "Connection failed. Verify your network settings."]
        }
    ]
    
    # Save to file
    filename = "custom_writing_rules.json"
    try:
        with open(filename, 'w') as f:
            json.dump(custom_rules, f, indent=2)
        
        print(f"‚úÖ Created {filename} with {len(custom_rules)} custom rules:")
        for rule in custom_rules:
            print(f"  ‚Ä¢ {rule['category']}: {rule['text'][:60]}...")
        
        return filename
        
    except Exception as e:
        print(f"‚ùå Error creating custom rules: {e}")
        return None

def test_with_custom_knowledge():
    """Test the RAG system with custom knowledge"""
    print("\nüß™ Testing RAG with Custom Knowledge")
    print("=" * 40)
    
    try:
        sys.path.append('scripts')
        from docscanner_ollama_rag import DocScannerOllamaRAG
        
        # Create new RAG system (will load custom rules automatically)
        rag_system = DocScannerOllamaRAG()
        
        # Test system status
        status = rag_system.test_system()
        print(f"System status: {status['status']}")
        print(f"Model: {status.get('model', 'Unknown')}")
        
        if status.get('available', False):
            print("‚úÖ RAG system working with custom knowledge!")
            
            # Test with scenarios that should trigger custom rules
            test_scenarios = [
                {
                    "feedback": "Use direct addressing instead of third person",
                    "sentence": "The user should click the save button to continue.",
                    "expected": "Direct addressing (you)"
                },
                {
                    "feedback": "Remove hedging language for clearer instructions", 
                    "sentence": "The system might possibly restart after the update.",
                    "expected": "Definitive language"
                },
                {
                    "feedback": "Improve error message clarity",
                    "sentence": "Error 404: Resource not accessible.",
                    "expected": "Clearer error message"
                }
            ]
            
            for i, test in enumerate(test_scenarios, 1):
                print(f"\nüìù Test {i}: {test['expected']}")
                print(f"Original: {test['sentence']}")
                
                result = rag_system.get_rag_suggestion(
                    feedback_text=test['feedback'],
                    sentence_context=test['sentence'],
                    document_type="technical"
                )
                
                if result:
                    suggestion = result['suggestion']
                    print(f"AI Suggestion: {suggestion[:120]}...")
                    print(f"Model: {result.get('model', 'unknown')}")
                    
                    # Check if suggestion seems to address the custom rule
                    if 'you' in suggestion.lower() and 'user' not in suggestion.lower():
                        print("üéØ Custom rule applied: Direct addressing!")
                    elif 'will' in suggestion or 'must' in suggestion:
                        print("üéØ Custom rule applied: Definitive language!")
                    elif len(suggestion) > len(test['sentence']):
                        print("üéØ Enhanced suggestion detected!")
                else:
                    print("‚ö†Ô∏è  No suggestion generated")
            
            return True
        else:
            print(f"‚ùå RAG system not available: {status.get('reason', 'Unknown')}")
            return False
            
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_model_upgrade_options():
    """Show available model upgrade options"""
    print("\nü§ñ Model Upgrade Options")
    print("=" * 40)
    
    # Check what models are currently available
    import subprocess
    
    try:
        result = subprocess.run(["ollama", "list"], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("Currently installed models:")
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if line.strip() and not line.startswith('NAME'):
                    print(f"  ‚úÖ {line}")
        else:
            print("‚ùå Could not check installed models")
            
    except Exception as e:
        print(f"‚ùå Error checking models: {e}")
    
    print("\nüí° Recommended upgrades:")
    
    upgrades = [
        {
            "name": "mistral:latest",
            "size": "~4.1GB", 
            "benefits": "Better reasoning, more coherent suggestions",
            "command": "ollama pull mistral:latest"
        },
        {
            "name": "phi3:mini",
            "size": "~2.3GB",
            "benefits": "Fast, efficient, good for writing tasks", 
            "command": "ollama pull phi3:mini"
        },
        {
            "name": "llama3:8b",
            "size": "~4.7GB",
            "benefits": "Excellent quality, comprehensive suggestions",
            "command": "ollama pull llama3:8b"
        }
    ]
    
    for upgrade in upgrades:
        print(f"\nüì¶ {upgrade['name']}")
        print(f"   Size: {upgrade['size']}")
        print(f"   Benefits: {upgrade['benefits']}")
        print(f"   Install: {upgrade['command']}")
    
    print("\n‚ö° Performance Tips:")
    print("‚Ä¢ Larger models = better quality but slower")
    print("‚Ä¢ phi3:mini is the best balance of speed/quality")
    print("‚Ä¢ mistral excels at writing and editing tasks")
    print("‚Ä¢ Test models with your specific use cases")

def show_fine_tuning_example():
    """Show a practical fine-tuning example"""
    print("\nüéØ Fine-Tuning Example")
    print("=" * 40)
    
    print("Fine-tune a model for your specific writing style:")
    
    example_modelfile = """
FROM phi3:mini

# Custom system prompt for your writing style
SYSTEM \"\"\"
You are a technical writing assistant specialized in clear, concise documentation.

Writing Style:
- Use active voice
- Write in present tense  
- Use "you" instead of "the user"
- Be direct and specific
- Include practical examples
- Avoid jargon and buzzwords

Format responses as complete sentence rewrites.
\"\"\"

# Example training data
TEMPLATE \"\"\"
User: {{.Prompt}}
Assistant: {{.Response}}
\"\"\"
"""
    
    print("1. Create a Modelfile:")
    print("```")
    print(example_modelfile)
    print("```")
    
    print("\n2. Create your custom model:")
    print("   ollama create my-docscanner-model -f Modelfile")
    
    print("\n3. Update DocScanner to use your model:")
    print("   Edit scripts/docscanner_ollama_rag.py")
    print("   Change: model='phi3:mini' to model='my-docscanner-model'")
    
    print("\n4. Benefits of fine-tuning:")
    print("   ‚Ä¢ Consistent with your writing style")
    print("   ‚Ä¢ Better understanding of your domain")
    print("   ‚Ä¢ More relevant suggestions")
    print("   ‚Ä¢ Faster, more focused responses")

def main():
    """Test upgrade features"""
    print("üöÄ DocScanner Ollama RAG Upgrade Test")
    print("=" * 50)
    
    # Create sample custom rules
    rules_file = create_sample_custom_rules()
    
    if rules_file:
        # Test with custom knowledge
        success = test_with_custom_knowledge()
        
        if success:
            print("\nüéâ Upgrade Features Working!")
            print("=" * 40)
            print("‚úÖ Custom knowledge integration")
            print("‚úÖ Enhanced AI suggestions")
            print("‚úÖ Domain-specific improvements")
        else:
            print("\n‚ö†Ô∏è  Some features need attention")
    
    # Show upgrade options
    show_model_upgrade_options()
    show_fine_tuning_example()
    
    print("\nüéØ Next Steps:")
    print("1. Try: python upgrade_ollama_rag.py (full upgrade guide)")
    print("2. Install a better model: ollama pull mistral:latest")
    print("3. Add your own writing rules to custom_writing_rules.json")
    print("4. Consider fine-tuning for your specific use case")

if __name__ == "__main__":
    main()
